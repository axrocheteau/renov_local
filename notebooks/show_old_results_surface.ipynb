{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append(os.path.abspath(\"../lib\"))\n",
    "from merge import prepare_train_show\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"renovation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# set this parameter for date issue before 1582 (dpe database)\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "# File location and type\n",
    "file_location_array = [\n",
    "    {\"location\": \"../training/pred_tremi_old.csv\",\n",
    "        \"name\": \"pred_tremi_old\", \"delimiter\": \",\"},\n",
    "    {\"location\": \"../training/pred_tremi.csv\",\n",
    "        \"name\": \"pred_tremi_full\", \"delimiter\": \",\"},\n",
    "    {\"location\": \"../training/dico.csv\", \"name\": \"dictionary\", \"delimiter\": \"\\t\"}\n",
    "]\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "dataframes = {}\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "for file in file_location_array:\n",
    "    delimiter = file[\"delimiter\"]\n",
    "    file_location = file[\"location\"]\n",
    "    name = file[\"name\"]\n",
    "    dataframes[file[\"name\"]] = (\n",
    "        spark.read.format(file_type)\n",
    "        .option(\"inferSchema\", infer_schema)\n",
    "        .option(\"header\", first_row_is_header)\n",
    "        .option(\"sep\", delimiter)\n",
    "        .load(file_location)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the important datasets and cast to type\n",
    "training_tremi_old = (\n",
    "    dataframes['pred_tremi_old'].withColumns({\n",
    "        'surface': F.col('surface').cast('int'),\n",
    "        'heating_production': F.col('heating_production').cast('int'),\n",
    "        'heating_emission': F.col('heating_emission').cast('int'),\n",
    "    })\n",
    ")\n",
    "training_tremi = (\n",
    "    dataframes['pred_tremi_full'].withColumns({\n",
    "        'surface': F.col('surface').cast('int'),\n",
    "        'heating_production': F.col('heating_production').cast('int'),\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "dictionary = dataframes['dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training_surf_old.count() =12565\n",
      "predicting_surf_old.count() =26933\n",
      "\n",
      "training_prod_old.count() =11128\n",
      "predicting_prod_old.count() =28370\n",
      "\n",
      "training_em_old.count() =12558\n",
      "predicting_em_old.count() =26940\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split training and prediction datasets\n",
    "training_surf_old = training_tremi_old.filter(F.col('surface').isNotNull()).drop('heating_emission', 'heating_production')\n",
    "predicting_surf_old = training_tremi_old.filter(F.col('surface').isNull()).drop('heating_emission', 'heating_production')\n",
    "\n",
    "training_prod_old = training_tremi_old.filter(F.col('heating_production').isNotNull()).drop('heating_emission', 'surface')\n",
    "predicting_prod_old = training_tremi_old.filter(F.col('heating_production').isNull()).drop('heating_emission', 'surface')\n",
    "\n",
    "training_em_old = training_tremi_old.filter(F.col('heating_emission').isNotNull()).drop('surface', 'heating_production')\n",
    "predicting_em_old = training_tremi_old.filter(F.col('heating_emission').isNull()).drop('surface', 'heating_production')\n",
    "\n",
    "print(f\"\"\"\n",
    "{training_surf_old.count() =}\n",
    "{predicting_surf_old.count() =}\\n\n",
    "{training_prod_old.count() =}\n",
    "{predicting_prod_old.count() =}\\n\n",
    "{training_em_old.count() =}\n",
    "{predicting_em_old.count() =}\\n\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training_surf.count() =12565\n",
      "predicting_surf.count() =26933\n",
      "\n",
      "training_prod.count() =11128\n",
      "predicting_prod.count() =28370\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split training and prediction datasets\n",
    "training_surf = training_tremi.filter(F.col('surface').isNotNull()).drop(\n",
    "    'heating_production')\n",
    "predicting_surf = training_tremi.filter(F.col('surface').isNull()).drop(\n",
    "    'heating_production')\n",
    "\n",
    "training_prod = training_tremi.filter(\n",
    "    F.col('heating_production').isNotNull()).drop('surface')\n",
    "predicting_prod = training_tremi.filter(\n",
    "    F.col('heating_production').isNull()).drop('surface')\n",
    "\n",
    "print(f\"\"\"\n",
    "{training_surf.count() =}\n",
    "{predicting_surf.count() =}\\n\n",
    "{training_prod.count() =}\n",
    "{predicting_prod.count() =}\\n\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
