{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.all import all_in_one\n",
    "from lib.show import show_hyperparam_opti\n",
    "from lib.train import iterate_params, choose_params, nb_possibility\n",
    "from lib.prepare_data import make_cut, to_categorical\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"renovation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# set this parameter for date issue before 1582 (dpe database)\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "# File location and type\n",
    "file_location_array = [\n",
    "    {\"location\": \"./training/pred_tremi.csv\",\n",
    "        \"name\": \"pred_tremi_full\", \"delimiter\": \",\"},\n",
    "    {\"location\": \"./training/dico.csv\", \"name\": \"dictionary\", \"delimiter\": \"\\t\"}\n",
    "]\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "dataframes = {}\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "for file in file_location_array:\n",
    "    delimiter = file[\"delimiter\"]\n",
    "    file_location = file[\"location\"]\n",
    "    name = file[\"name\"]\n",
    "    dataframes[file[\"name\"]] = (\n",
    "        spark.read.format(file_type)\n",
    "        .option(\"inferSchema\", infer_schema)\n",
    "        .option(\"header\", first_row_is_header)\n",
    "        .option(\"sep\", delimiter)\n",
    "        .load(file_location)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the important datasets and cast to type\n",
    "training_tremi = (\n",
    "    dataframes['pred_tremi_full'].withColumns({\n",
    "        'surface': F.col('surface').cast('float'),\n",
    "        'heating_production': F.col('heating_production').cast('int'),\n",
    "        'heating_emission': F.col('heating_emission').cast('int')\n",
    "    })\n",
    ")\n",
    "\n",
    "dictionary = dataframes['dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training_surf.count() =12565\n",
      "predicting_surf.count() =26933\n",
      "\n",
      "training_prod.count() =11128\n",
      "predicting_prod.count() =28370\n",
      "\n",
      "training_em.count() =12558\n",
      "predicting_em.count() =26940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split training and prediction datasets\n",
    "training_surf = training_tremi.filter(F.col('surface').isNotNull()).drop(\n",
    "    'heating_emission', 'heating_production')\n",
    "predicting_surf = training_tremi.filter(F.col('surface').isNull()).drop(\n",
    "    'heating_emission', 'heating_production')\n",
    "\n",
    "training_prod = training_tremi.filter(\n",
    "    F.col('heating_production').isNotNull()).drop('heating_emission', 'surface')\n",
    "predicting_prod = training_tremi.filter(\n",
    "    F.col('heating_production').isNull()).drop('heating_emission', 'surface')\n",
    "\n",
    "training_em = training_tremi.filter(\n",
    "    F.col('heating_emission').isNotNull()).drop('surface', 'heating_production')\n",
    "predicting_em = training_tremi.filter(\n",
    "    F.col('heating_emission').isNull()).drop('surface', 'heating_production')\n",
    "\n",
    "print(f\"\"\"\n",
    "{training_surf.count() =}\n",
    "{predicting_surf.count() =}\\n\n",
    "{training_prod.count() =}\n",
    "{predicting_prod.count() =}\\n\n",
    "{training_em.count() =}\n",
    "{predicting_em.count() =}\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 24\n",
      "max_resources_: 12565\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 24\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "0.861111111111111 {'n_estimators': 100, 'max_depth': 10, 'class_weight': 'balanced'}\n",
      "0.0992350886501304\n",
      "0 [1, 0, 0]\n",
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 24\n",
      "max_resources_: 12565\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 24\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "0.75 {'n_estimators': 100, 'max_depth': 10, 'class_weight': 'balanced'}\n",
      "0.14146438519697568\n",
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 24\n",
      "max_resources_: 12565\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 24\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "0.75 {'n_estimators': 100, 'max_depth': 10, 'class_weight': 'balanced'}\n",
      "0.22849184241941894\n",
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 24\n",
      "max_resources_: 12565\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 24\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "0.5555555555555556 {'n_estimators': 100, 'max_depth': 10, 'class_weight': 'balanced'}\n",
      "0.24494849007383826\n",
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 24\n",
      "max_resources_: 12565\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 24\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "0.5 {'n_estimators': 100, 'max_depth': 10, 'class_weight': 'balanced'}\n",
      "0.29888579387186626\n",
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 24\n",
      "max_resources_: 12565\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 24\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "0.75 {'n_estimators': 100, 'max_depth': 10, 'class_weight': 'balanced'}\n",
      "0.12904894548348583\n",
      "n_iterations: 1\n",
      "n_required_iterations: 1\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 24\n",
      "max_resources_: 12565\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1\n",
      "n_resources: 24\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    }
   ],
   "source": [
    "col_X_hot = [[]]\n",
    "col_y = ['surface']\n",
    "col_X_not_hot = [[col[0]\n",
    "                  for col in training_surf.dtypes if col[0] not in col_X_hot + col_y]]\n",
    "\n",
    "hyperparams_models = [\n",
    "    {\n",
    "        'n_estimators': [100],\n",
    "        # 'criterion' : [\"squared_error\", \"absolute_error\", \"friedman_mse\"],\n",
    "        'max_depth': [10],\n",
    "        'class_weight': ['balanced'],\n",
    "        # 'min_samples_split' : [2,5,10],\n",
    "        # 'min_samples_leaf' : [1,2,3],\n",
    "        # 'max_features' : [\"sqrt\", \"log2\", \"auto\"]\n",
    "    }\n",
    "]\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier\n",
    "}\n",
    "cut_params = {\n",
    "    'first_value': [30, 40, 50, 60, 70],\n",
    "    'steps': [25, 35, 45, 55, 65],\n",
    "    'nb_steps': [1, 2, 3]\n",
    "}\n",
    "\n",
    "current = [0 for _ in range(len(cut_params))]\n",
    "max_hyper = [len(cut_param) - 1 for cut_param in cut_params.values()]\n",
    "current_params = choose_params(current, cut_params)\n",
    "all_poss = nb_possibility(max_hyper)\n",
    "print(all_poss)\n",
    "\n",
    "cuts = make_cut(**current_params)\n",
    "categorical_surf, coef = to_categorical(training_surf, 'surface', cuts)\n",
    "# register score\n",
    "best_models = all_in_one(categorical_surf, dictionary, col_X_hot, col_X_not_hot, col_y, False,\n",
    "                         True, hyperparams_models, models, degree_poly=1, random_state=42, test_size=0.4, show=False)\n",
    "max_score = deepcopy(best_models['RandomForestClassifier'][1])\n",
    "best_split = deepcopy(current_params)\n",
    "scores = {}\n",
    "coefs = {}\n",
    "score_corrected = coef * best_models['RandomForestClassifier'][1]\n",
    "print(score_corrected)\n",
    "coefs[tuple([param for param in current_params.values()])] = deepcopy(coef)\n",
    "scores[tuple([param for param in current_params.values()])\n",
    "       ] = deepcopy(score_corrected)\n",
    "\n",
    "i = 0\n",
    "nb_print = (all_poss//4) + 1\n",
    "while not all(np.equal(current, max_hyper)):\n",
    "    # choose params\n",
    "    current = iterate_params(current, max_hyper)\n",
    "    current_params = choose_params(current, cut_params)\n",
    "    if i % nb_print == 0:\n",
    "        print(i, current)\n",
    "    i += 1\n",
    "    cuts = make_cut(**current_params)\n",
    "    categorical_surf, coef = to_categorical(training_surf, 'surface', cuts)\n",
    "    best_models = all_in_one(categorical_surf, dictionary, col_X_hot, col_X_not_hot, col_y, False,\n",
    "                             True, hyperparams_models, models, degree_poly=1, random_state=42, test_size=0.4, show=False)\n",
    "    score_corrected = coef * best_models['RandomForestClassifier'][1]\n",
    "    print(score_corrected)\n",
    "    scores[tuple([param for param in current_params.values()])\n",
    "           ] = deepcopy(score_corrected)\n",
    "    coefs[tuple([param for param in current_params.values()])] = deepcopy(coef)\n",
    "    if score_corrected > max_score:\n",
    "        max_score = deepcopy(score_corrected)\n",
    "        best_split = deepcopy(current_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax_hyper = plt.subplots(1, 1, figsize=(15, 5), sharey=True)\n",
    "# show_hyperparam_opti(coefs, cut_params, ax_hyper, 'surface_split')\n",
    "show_hyperparam_opti(scores, cut_params, ax_hyper, 'surface_split')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
