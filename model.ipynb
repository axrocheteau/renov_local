{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']= \"notebook\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"renovation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# set this parameter for date issue before 1582 (dpe database)\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create Database store raw files\n",
    "spark.sql(\"DROP DATABASE IF EXISTS datalake CASCADE\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS datalake\")\n",
    "\n",
    "# Create Database store modified files\n",
    "spark.sql(\"DROP DATABASE IF EXISTS gold CASCADE\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create database\n",
    "# File location and type\n",
    "file_location_array = [\n",
    "    {\"location\" : \"../../data/Communes.csv\", \"name\": \"pop_commune\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/Departements.csv\", \"name\": \"pop_department\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/PC_DP_creant_logements_2013_2016.csv\", \"name\": \"construction_licence\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/TREMI_2017_CodeBook_public8.txt\", \"name\": \"codebook\", \"delimiter\": \"\\t\"},\n",
    "    {\"location\" :  \"../../data/TREMI_2017_Résultats_enquête_bruts.csv\", \"name\": \"tremi\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/anciennes_nouvelles_regions.csv\", \"name\": \"former_new_region\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/code_commune.csv\", \"name\": \"code_commune\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/conso_elec_gaz_annuelle_par_secteur_dactivite_agregee_commune.csv\", \"name\": \"elec\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/donnees_synop_essentielles_omm.csv\", \"name\": \"weather\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/dpe_france.csv\", \"name\": \"dpe_france\", \"delimiter\": \",\"},\n",
    "    {\"location\" :  \"../../data/permis_amenager.csv\", \"name\": \"development_licence\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/permis_demolir.csv\", \"name\": \"destruction_licence\", \"delimiter\": \";\"},\n",
    "    {\"location\" :  \"../../data/dep_limitrophe.csv\", \"name\": \"neighbouring_dep\", \"delimiter\": \";\"}\n",
    "]\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "for file in file_location_array:\n",
    "    delimiter = file[\"delimiter\"]\n",
    "    file_location = file[\"location\"]\n",
    "    name = file[\"name\"]\n",
    "    df = spark.read.format(file_type) \\\n",
    "        .option(\"inferSchema\", infer_schema) \\\n",
    "        .option(\"header\", first_row_is_header) \\\n",
    "        .option(\"sep\", delimiter) \\\n",
    "        .load(file_location)\n",
    "    if name == \"weather\":\n",
    "        new_column_name_list= [name.replace(',','') for name in df.columns]\n",
    "        df = df.toDF(*new_column_name_list)\n",
    "    df.write.mode(\"overwrite\")\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(f\"datalake.{name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tremi = spark.sql(\"SELECT * FROM datalake.tremi\")\n",
    "pop_commune = spark.sql(\"SELECT * FROM datalake.pop_commune\")\n",
    "former_new_region = spark.sql(\"SELECT * FROM datalake.former_new_region\")\n",
    "dpe_france = spark.sql(\"SELECT * FROM datalake.dpe_france\")\n",
    "elec = spark.sql(\"SELECT * FROM datalake.elec\")\n",
    "construction_licence = spark.sql(\"SELECT * FROM datalake.construction_licence\")\n",
    "destruction_licence = spark.sql(\"SELECT * FROM datalake.destruction_licence\")\n",
    "development_licence = spark.sql(\"SELECT * FROM datalake.development_licence\")\n",
    "code_commune = spark.sql(\"SELECT * FROM datalake.code_commune\")\n",
    "pop_department = spark.sql(\"SELECT * FROM datalake.pop_department\")\n",
    "codebook = spark.sql(\"SELECT * FROM datalake.codebook\")\n",
    "weather_init = spark.sql(\"SELECT * FROM datalake.weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----+----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+----+----+----+----+----+----+----+----+----+\n",
      "|             NAME|VARNUM|               LABEL|            FORMAT|                  _1|                  _2|                  _3|                  _4|                  _5|                  _6|                  _7| _99|  _0|                  _8|                  _9|                 _10|                 _11|             _12|                 _13| _14| _15| _16| _17| _18| _19| _20| _21| _22|\n",
      "+-----------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----+----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+----+----+----+----+----+----+----+----+----+\n",
      "|Respondent_Serial|     1|   Respondent_Serial|              BEST|                null|                null|                null|                null|                null|                null|                null|null|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|    uniqueid_work|     2|       uniqueid_work|              BEST|                null|                null|                null|                null|                null|                null|                null|null|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "| Niveau_repondant|     3|Variable filtre -...|      _MAIN_Q1101_|                 Oui|                null|                null|                null|                null|                null|                null|  NR| Non|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|    Work_eligible|     4|Variable filtre -...|      _MAIN_Q1101_|                 Oui|                null|                null|                null|                null|                null|                null|  NR| Non|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|Logement_Eligible|     5|Variable filtre -...|      _MAIN_Q1101_|                 Oui|                null|                null|                null|                null|                null|                null|  NR| Non|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|     Var_eligible|     6|Variable filtre -...|      _MAIN_Q1101_|                 Oui|                null|                null|                null|                null|                null|                null|  NR| Non|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|       main_agglo|     7|       Agglomération|    _MAIN_ZDAGGLO_|               Rural|    2.000 à 20.000 H|  20.000 à 100.000 H|   Plus de 100.000 H|    Agglo parisienne|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|      main_region|     8|              Région|          _REGION_|Alsace, Champagne...|Aquitaine, Limous...|Auvergne, Rhône-A...|Bourgogne, Franch...|            Bretagne|              Centre|                null|  NR|null|              I.D.F.|Languedoc-Roussil...|Nord, Pas-de-Cala...|Basse-Normandie, ...|Pays de la Loire|Provence-Alpes-Cô...|null|null|null|null|null|null|null|null|null|\n",
      "|         main_rs1|     9|RS1 Sexe de la pe...|        _MAIN_RS1_|               Homme|               Femme|                null|                null|                null|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|      main_rs1ter|    10|RS1ter Sexe de la...|        _MAIN_RS1_|               Homme|               Femme|                null|                null|                null|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|         main_rs2|    11|RS2 Âge de la per...|       _RS2RS2TER_|     Moins de 25 ans|         25 à 34 ans|         35 à 49 ans|         50 à 64 ans|      65 ans et plus|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|      main_rs2ter|    12|RS2ter Âge de la ...|       _RS2RS2TER_|     Moins de 25 ans|         25 à 34 ans|         35 à 49 ans|         50 à 64 ans|      65 ans et plus|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|         main_rs3|    13|RS3 Etes-vous la ...|        _MAIN_RS3_|                 Oui|                 Non|                null|                null|                null|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|         main_rs5|    14|RS5 Actuellement,...|        _MAIN_RS5_|                 Oui|Non, chômeur ayan...|Non, retraité ou ...|Non, à la recherc...|Non, élève, étudiant|Non, femme/homme ...|Non, autre sans p...|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|         main_rs6|    15|RS6 Profession ac...|        _MAIN_RS6_|1 Agriculteur, vi...|2 Artisan, commer...|3 Profession libé...|4 Cadre de la fon...|5 Cadre d’entreprise|6 Profession inte...|7 Profession inte...|null|null|8 Technicien, con...|9 Employé de la f...|10 Ouvrier dans l...|          ST Inactif|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|      main_rs5rs6|    16|RS5/RS6 Professio...|_MAIN_ZD_RS6RECAP_|                PCS+|                PCS-|             Inactif|                null|                null|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|       main_RS102|    17|RS102 Nombre de p...|    _MAIN_ZDRS102_|          1 personne|         2 personnes|         3 personnes| 4 personnes et plus|                null|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|       main_RS182|    18|RS182 Revenus net...|      _MAIN_RS182_|Moins de 14 000 €...|De 14 000 à moins...|De 19 000 à moins...|De 25 000 à moins...|De 31 700 à moins...|De 40 000 à moins...|De 50 000 à moins...|  NR|null|De 60 000 à moins...|70 000 € par an e...|         Non réponse|         Non réponse|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|        main_Q100|    19|Q100 Statut résid...|       _MAIN_Q100_|     Locataire (HLM)|Locataire (non HL...|Propriétaire en a...|        Propriétaire|                null|                null|                null|  NR|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "|      main_q100_2|    20|Q100 Statut résid...|    _MAIN_Q100_ST_|        ST Locataire|     ST Propriétaire|                null|                null|                null|                null|                null|null|null|                null|                null|                null|                null|            null|                null|null|null|null|null|null|null|null|null|null|\n",
      "+-----------------+------+--------------------+------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----+----+--------------------+--------------------+--------------------+--------------------+----------------+--------------------+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "codebook.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, VARNUM: int, LABEL: string, answer_number: string, answer: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unpivotExpr = \"stack(24, '1', _1, '2', _2, '3', _3, '4', _4, '5', _5, '6', _6, '7', _7, '99', _99, '0', _0, '8', _8, '9', _9, '10', _10, '11', _11, '12', _12, '13', _13, '14', _14, '15', _15, '16', _16, '17', _17, '18', _18, '19', _19, '20', _20, '21', _21, '22', _22) AS (answer_number, answer)\"\n",
    "all_answer_df = codebook.select(\"Name\",\"VARNUM\",\"LABEL\", F.expr(unpivotExpr)).where(\"answer IS NOT NULL\")\n",
    "count_df = all_answer_df.groupBy(\"VARNUM\").count() # count number of possible answer to change multiplechoice question just for question with 3 answers : Yes, No ,NA\n",
    "display(all_answer_df)\n",
    "\n",
    "# get multiple questions answers and questions \n",
    "# template : question - answer \n",
    "# possible answer : Yes, No, N\n",
    "df_final = (\n",
    "    codebook.select(\n",
    "        \"VARNUM\", \n",
    "        F.regexp_extract(codebook['LABEL'], ' - (.*)', 1).alias('answer_char'),\n",
    "        F.regexp_extract(codebook['LABEL'], '(.*) - ', 1).alias('question_char'),\n",
    "        F.reverse(F.split(F.reverse(codebook['Name']),'_').getItem(0)).alias('answer_num')\n",
    "    )         \n",
    "    .join(count_df, [\"VARNUM\"], 'inner')\n",
    "    .join(all_answer_df, [\"VARNUM\"], 'inner')\n",
    ")\n",
    "\n",
    "# replace question with 3 answers by only one \n",
    "Dictionnary = (\n",
    "    df_final.select(\n",
    "        F.col('Name').alias('column_name'),\n",
    "        F.col('VARNUM').alias('varnum'),\n",
    "        (\n",
    "            F.when(\n",
    "                (df_final['question_char'] != '')\n",
    "                & (df_final['question_char'] != 'Variable filtre')\n",
    "                & (df_final['question_char'] !='BLOCS Travaux')\n",
    "                & (df_final['count']<=3), df_final['answer_char']\n",
    "            )\n",
    "            .otherwise(df_final['answer'])\n",
    "        )\n",
    "        .alias(\"answer_char\"),\n",
    "        (\n",
    "            F.when(\n",
    "                (df_final['question_char'] != '')\n",
    "                & (df_final['question_char'] != 'Variable filtre')\n",
    "                & (df_final['question_char'] !='BLOCS Travaux')\n",
    "                &  (df_final['count']<=3), df_final['answer_num']\n",
    "            )\n",
    "            .otherwise(df_final['answer_number'])\n",
    "        )\n",
    "        .alias(\"answer_number\"),\n",
    "        (\n",
    "            F.when(\n",
    "                (df_final['question_char'] != '')\n",
    "                & (df_final['question_char'] != 'Variable filtre')\n",
    "                & (df_final['question_char'] !='BLOCS Travaux')\n",
    "                &  (df_final['count']<=3), df_final['question_char']\n",
    "            )\n",
    "            .otherwise(df_final['LABEL'])\n",
    "        )\n",
    "        .alias(\"question\")\n",
    "    )\n",
    "    .drop_duplicates()\n",
    "    # Rename to fit scheme and order and add id\n",
    "    .select(\n",
    "        F.monotonically_increasing_id().alias('id_answer'),\n",
    "        \"*\"\n",
    "    )\n",
    ")\n",
    "# save as table\n",
    "Dictionnary.write.mode('overwrite')\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(\"Gold.Dictionnary\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpivot the data to get all answers for every interestting question\n",
    "unpivotExpr = \"stack(62, 'main_q2_1', main_q2_1, 'main_q2_2', main_q2_2, 'main_q2_3', main_q2_3, 'main_q2_4', main_q2_4, 'main_q2_5', main_q2_5, 'main_q2_6', main_q2_6, 'main_q2_7', main_q2_7, 'main_q2_8', main_q2_8, 'main_q3_1', main_q3_1, 'main_q3_2', main_q3_2, 'main_q3_3', main_q3_3, 'main_q3_4', main_q3_4, 'main_q3_5', main_q3_5, 'main_q3_6', main_q3_6, 'main_q3_7', main_q3_7, 'main_q4_1', main_q4_1, 'main_q4_2', main_q4_2, 'main_q4_3', main_q4_3, 'main_q4_4', main_q4_4, 'main_q4_5', main_q4_5, 'main_q4_6', main_q4_6, 'main_q4_7', main_q4_7, 'main_q4_8', main_q4_8, 'main_Q70_01', main_Q70_01, 'main_Q70_02', main_Q70_02, 'main_Q70_03', main_Q70_03, 'main_Q70_04', main_Q70_04, 'main_Q70_05', main_Q70_05, 'main_Q70_06', main_Q70_06, 'main_Q70_07', main_Q70_07, 'main_Q70_08', main_Q70_08, 'main_Q70_09', main_Q70_09, 'main_Q70_10', main_Q70_10, 'main_Q70_11', main_Q70_11, 'main_Q70_12', main_Q70_12, 'main_Q70_13', main_Q70_13, 'main_Q70_14', main_Q70_14, 'main_Q71_01', main_Q71_01, 'main_Q71_03', main_Q71_03, 'main_Q71_04', main_Q71_04, 'main_Q71_05', main_Q71_05, 'main_Q71_06', main_Q71_06, 'main_Q71_07', main_Q71_07, 'main_Q71_08', main_Q71_08, 'main_Q71_09', main_Q71_09, 'main_Q71_10', main_Q71_10, 'main_Q71_11', main_Q71_11, 'main_Q71_12', main_Q71_12, 'main_Q71_13', main_Q71_13, 'main_Q71_14', main_Q71_14, 'main_Q74_1', main_Q74_1, 'main_Q74_2', main_Q74_2, 'main_Q74_3', main_Q74_3, 'main_Q74_4', main_Q74_4, 'main_Q74_5', main_Q74_5, 'main_q81_1', main_q81_1, 'main_q81_2', main_q81_2, 'main_q81_3', main_q81_3, 'main_q81_4', main_q81_4, 'main_q81_5', main_q81_5, 'main_q81_6', main_q81_6, 'main_q81_7', main_q81_7) AS (column_name, answer)\"\n",
    "all_answer_df = tremi.select(F.col(\"Respondent_Serial\").alias('id_owner'), F.expr(unpivotExpr)).where(\"answer == 1\").dropDuplicates()\n",
    "\n",
    "# join with dictionnary to do an association table\n",
    "answer = (\n",
    "    all_answer_df.join(\n",
    "        Dictionnary, ['column_name'], 'inner'\n",
    "    )\n",
    "    .select('id_owner', 'id_answer')\n",
    ")\n",
    "\n",
    "# save as table\n",
    "answer.write.mode('overwrite')\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(\"Gold.Answer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner = (\n",
    "    tremi.select(\n",
    "        F.col('Respondent_Serial').alias('id_owner'),\n",
    "        F.col('main_rs1').alias('gender'),\n",
    "        F.col('main_rs2_c').alias('age'),\n",
    "        F.col('main_rs5').alias('work_state'),\n",
    "        F.col('main_rs6').alias('job'),\n",
    "        F.col('main_Q100').alias('home_state'),\n",
    "        F.col('main_Q44').alias('arrival_date'),\n",
    "        F.col('main_Q1_97').alias('has_done_renov'),\n",
    "        F.col('main_rs102_c').alias('nb_persons_home'),\n",
    "        F.col('main_RS182').alias('income_home'),\n",
    "        F.col('main_Q73').alias('amount_help'),\n",
    "        F.col('main_Q75').alias('loan_amount'),\n",
    "        F.col('main_Q76').alias('loan_duration'),\n",
    "        F.col('main_q77').alias('loan_rate')\n",
    "    )\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "# save as table\n",
    "owner.write.mode('overwrite')\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(\"Gold.Owner\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = (\n",
    "    tremi.select(   \n",
    "        F.col('Respondent_Serial').alias('id_owner'),\n",
    "        F.when(F.col('cd_postal') < 10000, F.concat(F.lit(\"0\"), F.col('cd_postal').cast('string')))\n",
    "            .otherwise(F.col('cd_postal').cast('string'))\n",
    "            .alias('cd_postal'),\n",
    "        F.col('main_Q101').alias('type'),\n",
    "        F.col('main_Q102').alias('construction_date'),\n",
    "        F.col('main_Q103').alias('heating_system'),\n",
    "        F.col('main_Q104').alias('hot_water_system'),\n",
    "        F.col('main_Q41q42').alias('surface'),\n",
    "        F.col('main_Q1_97').alias('has_done_renov'),\n",
    "        F.col('main_Q43').alias('DPE_before'),\n",
    "        F.col('main_Q52').alias('thermal_comfort'),\n",
    "        F.col('main_Q53').alias('energy_reduction'),\n",
    "        F.col('main_Q38').alias('adjoining'),\n",
    "        F.col('main_Q39').alias('n_floors'),\n",
    "        F.col('main_Q40').alias('floor_nb')\n",
    "    )\n",
    "    .dropDuplicates()\n",
    "    .select(F.monotonically_increasing_id().alias('id_housing'),\"*\")\n",
    ")\n",
    "\n",
    "# save as table\n",
    "housing.write.mode('overwrite')\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(\"Gold.Housing\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = (\n",
    "    development_licence.select( #table that link region and dep number\n",
    "        F.col('REG').alias('former_region_number'),\n",
    "        F.col('DEP').alias('department_number')\n",
    "    )\n",
    "    .dropDuplicates() # to reduce number of value drastically\n",
    "    .join(\n",
    "        pop_department.select( # to get department name\n",
    "                F.col('CODDEP').alias('department_number'),\n",
    "                F.col('DEP').alias('department_name')\n",
    "            ),\n",
    "        ['department_number'],\n",
    "        'inner'\n",
    "    )\n",
    "    .join(\n",
    "        former_new_region.select( # to get all region info\n",
    "                F.col('Nouveau Code').alias('new_region_number'),\n",
    "                F.col('Nouveau Nom').alias('new_region_name'),\n",
    "                F.col('Anciens Code').alias('former_region_number'),\n",
    "                F.col('Anciens Nom').alias('former_region_name')\n",
    "            ),\n",
    "        ['former_region_number'],\n",
    "        'inner'\n",
    "    )\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "df_commune = (\n",
    "    pop_commune.select( # populations info\n",
    "        F.col('DEPCOM').alias('code_insee'),\n",
    "        F.col('COM').alias('commune_name'),\n",
    "        F.col('PMUN').alias('population'),\n",
    "        F.col('DEPCOM').substr(0,2).alias('department_number')\n",
    "    )\n",
    "    .join( # dpe and ges info\n",
    "        dpe_france.filter( # only take dpe between 2014 and 2016, ges and dpe that are relevant  \n",
    "                (F.col('date_etablissement_dpe').between(F.lit(\"2014-01-01\"), F.lit(\"2017-01-01\"))) &\n",
    "                (F.col('classe_consommation_energie') != 'N') &\n",
    "                (F.col('classe_estimation_ges') != 'N') # N is not a valid dpe or ges\n",
    "            )\n",
    "            .select( # put ges and dpe as float to average them\n",
    "                F.when(F.col('classe_consommation_energie') == 'A', 1.0)\n",
    "                    .when(F.col('classe_consommation_energie') == 'B', 2.0)\n",
    "                    .when(F.col('classe_consommation_energie') == 'C', 3.0)\n",
    "                    .when(F.col('classe_consommation_energie') == 'D', 4.0)\n",
    "                    .when(F.col('classe_consommation_energie') == 'E', 5.0)\n",
    "                    .when(F.col('classe_consommation_energie') == 'F', 6.0)\n",
    "                    .when(F.col('classe_consommation_energie') == 'G', 7.0)\n",
    "                    .otherwise(0.0)\n",
    "                    .alias('dpe'),\n",
    "                F.when(F.col('classe_estimation_ges') == 'A', 1.0)\n",
    "                    .when(F.col('classe_estimation_ges') == 'B', 2.0)\n",
    "                    .when(F.col('classe_estimation_ges') == 'C', 3.0)\n",
    "                    .when(F.col('classe_estimation_ges') == 'D', 4.0)\n",
    "                    .when(F.col('classe_estimation_ges') == 'E', 5.0)\n",
    "                    .when(F.col('classe_estimation_ges') == 'F', 6.0)\n",
    "                    .when(F.col('classe_estimation_ges') == 'G', 7.0)\n",
    "                    .otherwise(0.0)\n",
    "                    .alias('ges'),\n",
    "                F.col('code_insee_commune_actualise').alias('code_insee')\n",
    "            )\n",
    "            .groupBy('code_insee').agg(F.avg('dpe'), F.avg('ges'), F.count('code_insee'))\n",
    "            .select(\n",
    "                F.col('code_insee'),\n",
    "                F.round(F.col('avg(dpe)'),2).alias('avg_dpe'),\n",
    "                F.round(F.col('avg(ges)'),2).alias('avg_ges'),\n",
    "                F.col('count(code_insee)').alias('n_dpe')\n",
    "            ),\n",
    "        ['code_insee'],\n",
    "        'left_outer'\n",
    "    )\n",
    "    .join( # elec consumption info\n",
    "        elec.filter( # only take electricity conumption between 2014 and 2016\n",
    "                (F.col('Année').between(2014, 2016)) &\n",
    "                (F.col('Filière') == 'Electricité')\n",
    "            )\n",
    "            .select(\n",
    "                (F.col('Consommation Résidentiel  (MWh)') / F.col('Nombre de points Résidentiel')).alias('consumption_by_residence'),\n",
    "                F.col('Code Commune').alias('code_insee')\n",
    "            )\n",
    "            .where('consumption_by_residence IS NOT NULL')\n",
    "            .groupBy('code_insee').agg(F.round(F.avg('consumption_by_residence'),2).alias('consumption_by_residence')),\n",
    "        ['code_insee'],\n",
    "        'left_outer'\n",
    "    )\n",
    "    .join( # get postal codes\n",
    "        code_commune.select(\n",
    "            F.col('Code_commune_INSEE').alias('code_insee'),\n",
    "            # correct postal codes interpreted as int\n",
    "            F.when(F.col('Code_postal') < 10000, F.concat(F.lit(\"0\"), F.col('Code_postal').cast('string')))\n",
    "                .otherwise(F.col('Code_postal').cast('string'))\n",
    "                .alias('cd_postal')\n",
    "            ),\n",
    "        ['code_insee'],\n",
    "        'left_outer'\n",
    "    )\n",
    "    .join( # get construction licence\n",
    "        construction_licence.filter(\n",
    "                F.col('DATE_REELLE_AUTORISATION').between(F.lit(\"2014-01-01\"), F.lit(\"2017-01-01\"))\n",
    "            )\n",
    "            .select(\n",
    "                F.col('NB_LGT_TOT_CREES').alias('nb_housing'),\n",
    "                F.col('COMM').alias('code_insee')\n",
    "            )\n",
    "            .groupBy('code_insee').agg(F.sum('nb_housing').alias('n_construction_licence')),\n",
    "        ['code_insee'],\n",
    "        'left_outer'\n",
    "    )\n",
    "    .join( # get destruction licence\n",
    "        destruction_licence.filter(\n",
    "                F.col('DATE_REELLE_AUTORISATION').between(F.lit(\"2014-01-01\"), F.lit(\"2017-01-01\"))\n",
    "            )\n",
    "            .select(\n",
    "                F.col('COMM').alias('code_insee')\n",
    "            )\n",
    "            .groupBy('code_insee').agg(F.count('code_insee').alias('n_destruction_licence')),\n",
    "        ['code_insee'],\n",
    "        'left_outer'\n",
    "    )\n",
    "    .join( # get development licence\n",
    "        development_licence.filter(\n",
    "                F.col('DATE_REELLE_AUTORISATION').between(F.lit(\"2014-01-01\"), F.lit(\"2017-01-01\"))\n",
    "            )\n",
    "            .select(\n",
    "                F.col('COMM').alias('code_insee')\n",
    "            )\n",
    "            .groupBy('code_insee').agg(F.count('code_insee').alias('n_development_licence')),\n",
    "        ['code_insee'],\n",
    "        'left_outer'\n",
    "    )\n",
    "    .join( # get regions info and dep name\n",
    "        regions,\n",
    "        ['department_number'],\n",
    "        'inner'\n",
    "    )\n",
    "    .withColumns({ # put null values to 0 to make sense\n",
    "        'n_development_licence': F.when(F.col('n_development_licence').isNull(), 0).otherwise(F.col('n_development_licence')),\n",
    "        'n_destruction_licence': F.when(F.col('n_destruction_licence').isNull(), 0).otherwise(F.col('n_destruction_licence')),\n",
    "        'n_construction_licence': F.when(F.col('n_construction_licence').isNull(), 0).otherwise(F.col('n_construction_licence')),\n",
    "        'n_dpe': F.when(F.col('n_dpe').isNull(), 0).otherwise(F.col('n_dpe')),\n",
    "        # add an id for every town\n",
    "        \"id_commune\": F.monotonically_increasing_id()\n",
    "    })\n",
    ")\n",
    "\n",
    "# reorder columns\n",
    "df_commune = df_commune.select(\n",
    "    'id_commune',\n",
    "    'cd_postal',\n",
    "    'code_insee',\n",
    "    'commune_name',\n",
    "    'department_number',\n",
    "    'department_name',\n",
    "    'former_region_name',\n",
    "    'former_region_number',\n",
    "    'new_region_name',\n",
    "    'new_region_number',\n",
    "    'population',\n",
    "    'n_development_licence',\n",
    "    'n_construction_licence',\n",
    "    'n_destruction_licence',\n",
    "    'n_dpe',\n",
    "    'avg_dpe',\n",
    "    'avg_ges',\n",
    "    'consumption_by_residence'\n",
    ")\n",
    "\n",
    "# save as table\n",
    "df_commune.write.mode('overwrite')\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(\"Gold.Commune\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renovation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_renov: bigint, id_owner: int, work_type: string, work_type_number: int, start_date: int, end_date: int, done_by: int, amount: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stack_expr = \"stack(21, Respondent_Serial, 'roof_with_insulation', 11, main_Q5_11, main_Q6_11, main_Q18_11, main_Q20_11, Respondent_Serial, 'rooth_without_insulation', 12, main_Q5_12, main_Q6_12, main_Q18_12, main_Q20_12, Respondent_Serial, 'insulation_roof_without_renovation', 13, main_Q5_13, main_Q6_13, main_Q18_13, main_Q20_13, Respondent_Serial, 'insulation_flooring_attic', 14, main_Q5_14, main_Q6_14, main_Q18_14, main_Q20_14, Respondent_Serial, 'roof_terrace_with_insulation', 15, main_Q5_15, main_Q6_15, main_Q18_15, main_Q20_15, Respondent_Serial, 'roof_terrase_without_insulation', 16, main_Q5_16, main_Q6_16, main_Q18_16, main_Q20_16, Respondent_Serial, 'ext_wall_with_insulation', 21, main_Q5_21, main_Q6_21, main_Q18_21, main_Q20_21, Respondent_Serial, 'ext_wall_without_insulation', 22, main_Q5_22, main_Q6_22, main_Q18_22, main_Q20_22, Respondent_Serial, 'int_wall_with_insulation', 23, main_Q5_23, main_Q6_23, main_Q18_23, main_Q20_23, Respondent_Serial, 'int_wall_without_insulation', 24, main_Q5_24, main_Q6_24, main_Q18_24, main_Q20_24, Respondent_Serial, 'down_flooring_with_insulation', 31, main_Q5_31, main_Q6_31, main_Q18_31, main_Q20_31, Respondent_Serial, 'down_flooring_without_insulation', 32, main_Q5_32, main_Q6_32, main_Q18_32, main_Q20_32, Respondent_Serial, 'opening_common_areas', 41, main_Q5_41, main_Q6_41, NULL, NULL, Respondent_Serial, 'opening_accomodation', 42, main_Q5_42, main_Q6_42, main_Q18_42, main_Q20_42, Respondent_Serial, 'ext_doors', 43, main_Q5_43, main_Q6_43, main_Q18_43, main_Q20_43, Respondent_Serial, 'heating_system', 51, main_Q5_51, main_Q6_51, main_Q18_51, main_Q20_51, Respondent_Serial, 'heating_regulation', 52, main_Q5_52, main_Q6_52, main_Q18_52, main_Q20_52, Respondent_Serial, 'hot_water', 53, main_Q5_53, main_Q6_53, main_Q18_53, main_Q20_53, Respondent_Serial, 'insulation', 54, main_Q5_54, main_Q6_54, main_Q18_54, main_Q20_54, Respondent_Serial, 'ventilation_system', 55, main_Q5_55, main_Q6_55, main_Q18_55, main_Q20_55, Respondent_Serial, 'air_consitioning_system', 56, main_Q5_56, main_Q6_56, main_Q18_56, main_Q20_56) AS (id_owner, work_type, work_type_number, start_date, end_date, done_by, amount)\"\n",
    "\n",
    "renovation = (\n",
    "    tremi.select(F.expr(stack_expr))\n",
    "    .where(\"start_date IS NOT NULL\") # select only renovation that have been done\n",
    "    .dropDuplicates()\n",
    "    .select(F.monotonically_increasing_id().alias('id_renov'), \"*\") # add id\n",
    ")\n",
    "display(renovation)\n",
    "\n",
    "# save as table\n",
    "renovation.write.mode('overwrite')\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(\"Gold.Renovation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = (\n",
    "    weather_init.select(\n",
    "        F.col(\"Direction du vent moyen 10 mn\").alias('wind_direction'),\n",
    "        F.col(\"Vitesse du vent moyen 10 mn\").alias('wind_speed'),\n",
    "        F.col(\"Température\").alias('temp_kelvin'),\n",
    "        F.col(\"Humidité\").alias('humidity'),\n",
    "        F.col(\"Hauteur de la base des nuages de l'étage inférieur\").alias('heigh_clouds'),\n",
    "        F.col(\"Température (°C)\").alias('temp_degree'),\n",
    "        F.col(\"Altitude\").alias('altitude'),\n",
    "        F.col(\"department (code)\").alias('department_number'),\n",
    "        F.col(\"mois_de_l_annee\").alias('month'),\n",
    "        F.year(\"Date\").alias('year')\n",
    "    )\n",
    "    .groupBy('month', 'year', 'department_number').avg()\n",
    "    .select(\n",
    "        'department_number',\n",
    "        'year',\n",
    "        'month',\n",
    "        F.round(F.col('avg(wind_direction)'),2).alias('wind_direction'),\n",
    "        F.round(F.col('avg(wind_speed)'),2).alias('wind_speed'),\n",
    "        F.round(F.col('avg(temp_kelvin)'),2).alias('temp_kelvin'),\n",
    "        F.round(F.col('avg(humidity)'),2).alias('humidity'),\n",
    "        F.round(F.col('avg(heigh_clouds)'),2).alias('heigh_clouds'),\n",
    "        F.round(F.col('avg(temp_degree)'),2).alias('temp_degree'),\n",
    "        F.round(F.col('avg(altitude)'),2).alias('altitude')\n",
    "    )\n",
    ")\n",
    "\n",
    "# get data for departments that are not in the dataset\n",
    "\n",
    "neigh = spark.sql(\"SELECT * FROM datalake.neighbouring_dep\") # get neighbouring department\n",
    "unpivotExpr = \"stack(8, Voisin_1, Voisin_2, Voisin_3, Voisin_4, Voisin_5, Voisin_6, Voisin_7, Voisin_8) AS (neigh)\"\n",
    "neigh = neigh.select(\"Departement\", F.expr(unpivotExpr)).where(\"neigh IS NOT NULL\")\n",
    "\n",
    "# get all departments that are not present in weather dataset\n",
    "all_possible_not_dep = (\n",
    "    neigh.join(\n",
    "        weather.select('year', 'month').dropDuplicates()\n",
    "    )\n",
    "    .withColumnRenamed(\"Departement\", \"department_number\")\n",
    "    .join(\n",
    "        weather.select('department_number', 'year', 'month').dropDuplicates(),\n",
    "        ['department_number', 'month', 'year'],\n",
    "        'left_anti'\n",
    "    )\n",
    ")\n",
    "\n",
    "full_weather = (\n",
    "    all_possible_not_dep.withColumnRenamed('department_number', 'Departement') \n",
    "    .withColumnRenamed('neigh', 'department_number') # to join on neighbors easier this way\n",
    "    .join(weather, ['department_number', 'month', 'year']) # get existing values for neighbors for every date\n",
    "    .groupBy('Departement', 'month', 'year').avg() # get average for every date and neighbor\n",
    "    .select(\n",
    "        F.col('Departement').alias('department_number'),\n",
    "        'year',\n",
    "        'month',\n",
    "        F.round(F.col('avg(wind_direction)'),2).alias('wind_direction'),\n",
    "        F.round(F.col('avg(wind_speed)'),2).alias('wind_speed'),\n",
    "        F.round(F.col('avg(temp_kelvin)'),2).alias('temp_kelvin'),\n",
    "        F.round(F.col('avg(humidity)'),2).alias('humidity'),\n",
    "        F.round(F.col('avg(heigh_clouds)'),2).alias('heigh_clouds'),\n",
    "        F.round(F.col('avg(temp_degree)'),2).alias('temp_degree'),\n",
    "        F.round(F.col('avg(altitude)'),2).alias('altitude')\n",
    "    ) # rename columns\n",
    "    .union(weather) # get data for all departements\n",
    "    .where(\"department_number IS NOT NULL\") # remove unrelevant data\n",
    "    .withColumn('department_number', F.when(F.length('department_number') == 1, F.concat(F.lit(\"0\"), F.col('department_number'))) # uniformise department number\n",
    "        .otherwise(F.col('department_number'))\n",
    "    ) \n",
    ")\n",
    "\n",
    "# save as table\n",
    "full_weather.write.mode('overwrite')\\\n",
    "        .format(\"parquet\") \\\n",
    "        .saveAsTable(\"Gold.Weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dictionnary = spark.sql(\"SELECT * FROM Gold.Dictionnary\")\n",
    "Answer = spark.sql(\"SELECT * FROM Gold.Answer\")\n",
    "Owner = spark.sql(\"SELECT * FROM Gold.Owner\")\n",
    "Housing = spark.sql(\"SELECT * FROM Gold.Housing\")\n",
    "Commune = spark.sql(\"SELECT * FROM Gold.Commune\")\n",
    "Renovation = spark.sql(\"SELECT * FROM Gold.Renovation\")\n",
    "Weather = spark.sql(\"SELECT * FROM Gold.Weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
